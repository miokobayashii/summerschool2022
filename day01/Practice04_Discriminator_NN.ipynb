{"cells":[{"cell_type":"markdown","metadata":{"id":"c9QSR9wl1nN5"},"source":["## Discriminator with NN\n","\n","We use mnist dataset.\n","\n","Assume that images of ONE are REAL(1), and those of SEVEN are FAKE(0).\n","\n","We investigate whether a discriminator can distinguish if it is ONE or SEVEN.\n","\n","<img src=\"https://docs.google.com/uc?id=1XXmgT15DAbcN1tNI8OvefeTdq4cevU40\" width=\"300\">\n","\n","\n","<img src=\"https://docs.google.com/uc?id=1RyU-ML85aiOLyT1BnmKSwdhqeC-AyqNV\" width=\"600\">"]},{"cell_type":"markdown","metadata":{"id":"KegDChVIa_-T"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/miokobayashii/summerschool2022/blob/main/day01/Practice04_Discriminator_NN.ipynb)"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":468,"status":"ok","timestamp":1659263559006,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"},"user_tz":-540},"id":"CF_GyHCD1mY4"},"outputs":[],"source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from keras.datasets import mnist\n","from keras.layers import Dense, Flatten, Reshape\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.models import Sequential\n","#from keras.optimizers import Adam\n","from keras.optimizers import adam_v2\n","from keras.utils.vis_utils import plot_model\n","#from tensorflow.keras.utils import plot_model"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659263561060,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"},"user_tz":-540},"id":"U10iLo3n1ymd"},"outputs":[],"source":["img_rows = 28\n","img_cols = 28\n","channels = 1\n","\n","img_shape = (img_rows, img_cols, channels)    "]},{"cell_type":"markdown","source":["### Disctiminator\n","\n","As an input layer, Flatten layer is used."],"metadata":{"id":"4EZnfIGS0RzP"}},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":253,"status":"ok","timestamp":1659263626806,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"},"user_tz":-540},"id":"qM6lX_WQ12Jl"},"outputs":[],"source":["def build_discriminator(img_shape):\n","\n","    model = Sequential()\n","\n","    # Flatten the input image\n","    model.add(Flatten(input_shape=img_shape))\n","    \n","    # Fully connected layer\n","    model.add(Dense(128))\n","\n","    # Leaky ReLU activation\n","    model.add(LeakyReLU(alpha=0.01))\n","\n","    # Output layer with sigmoid activation\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xSVDCBRX13GU"},"outputs":[],"source":["discriminator = build_discriminator(img_shape)\n","discriminator.compile(loss='binary_crossentropy',\n","                      optimizer=adam_v2.Adam(),\n","                      metrics=['accuracy'])\n","discriminator.summary()\n","plot_model(discriminator, to_file='model.png', show_shapes=True)\n"]},{"cell_type":"markdown","source":["### Load MNIST dataset and confirm images of handwritten digits"],"metadata":{"id":"o9OZ5t_f0exn"}},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":700,"status":"ok","timestamp":1659263696361,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"},"user_tz":-540},"id":"MgukTQKD63CD"},"outputs":[],"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1659263697862,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"},"user_tz":-540},"id":"1Iirt2I_A-MJ","outputId":"17a1a658-4622-438a-f981-27386e0a9233"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"]},"metadata":{},"execution_count":45}],"source":["X_train.shape, y_train.shape, X_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":278,"status":"ok","timestamp":1659263703655,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"},"user_tz":-540},"id":"tr7orXhMGl3p"},"outputs":[],"source":["def show_img(img, figsize=(2,2)):\n","    fig = plt.figure(figsize=figsize,dpi=100)\n","    plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n","    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_G4OSyA2GqJq"},"outputs":[],"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","char = 9\n","X_test = X_test[np.where(y_test==char)]  \n","[idx] = np.random.randint(0, X_test.shape[0], 1)\n","show_img(X_test[idx])"]},{"cell_type":"code","source":["for i in range(28):\n","  for j in range(28):\n","    s = str(X_test[idx][i][j])\n","    s_ljust = s.rjust(4,'_')\n","    print(s_ljust, end=\"\")\n","  \n","  print(\"\")"],"metadata":{"id":"D9AIaIOyu7cB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Trainning process\n","In Practice02_DefineLossFunctionOptimizer.ipynb, we used \"model.fit()\" to train the model, but here we use iterations and \"discriminator.train_on_batch()\" instead. That is because we can extend the program to train a generator network later."],"metadata":{"id":"sl5lBqv0wjkM"}},{"cell_type":"code","execution_count":91,"metadata":{"id":"r_afy2X12E3w","executionInfo":{"status":"ok","timestamp":1659264867616,"user_tz":-540,"elapsed":270,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"outputs":[],"source":["losses = []\n","accuracies = []\n","iteration_checkpoints = []\n","\n","def train(batch_size, sample_interval, n_epochs = 1):\n","\n","    # Load the MNIST dataset\n","    (X_train, _), (_, _) = mnist.load_data()\n","\n","    char = 1 #True image\n","    X_train_1 = X_train[np.where(y_train==char)]    \n","\n","    char = 7 #Fake image\n","    X_train_7 = X_train[np.where(y_train==char)]  \n","\n","    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n","    X_train_1 = X_train_1 / 127.5 - 1.0\n","    X_train_7 = X_train_7 / 127.5 - 1.0\n","\n","    #for iteration in range(iterations):\n","    bat_per_epo = int((X_train_1.shape[0] + X_train_7.shape[0]) / batch_size)\n","    half_batch = int(batch_size / 2)\n","    print(bat_per_epo, half_batch )\n","    # Labels for real images: all ones\n","    real = np.ones((half_batch, 1))\n","    # Labels for fake images: all zeros\n","    fake = np.zeros((half_batch, 1))\n","\n","    for i in range(n_epochs):\n","        for j in range(bat_per_epo):\n","\n","          # -------------------------\n","          #  Train the Discriminator\n","          # -------------------------\n","\n","          # Get a random batch of real images\n","          idx = np.random.randint(0, X_train_1.shape[0], half_batch)\n","          imgs = X_train_1[idx]\n","\n","          # Get a random batch of fake images\n","          idx = np.random.randint(0, X_train_7.shape[0], half_batch)\n","          fake_img = X_train_7[idx]\n","\n","          # Train Discriminator\n","          d_loss_real = discriminator.train_on_batch(imgs, real)\n","          d_loss_fake = discriminator.train_on_batch(fake_img , fake)\n","          # print(d_loss_real, d_loss_fake)\n","          d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","\n","          if (i*10 +  j + 1) % sample_interval == 0 :\n","\n","                # Save losses and accuracies so they can be plotted after training\n","                losses.append((d_loss))\n","                accuracies.append(100.0 * accuracy)\n","                iteration_checkpoints.append(i*10 +  j + 1)\n","\n","                # Output training progress\n","                print(\"Epoch:%d %d/%d [D loss: %f, acc.: %.2f%%]\" %\n","                      (i + 1, j+1, bat_per_epo, d_loss, 100.0 * accuracy))\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":240,"status":"ok","timestamp":1656652566093,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"},"user_tz":-540},"id":"dkHJB90ZDumY","outputId":"9abf8cde-6af4-4fc5-8f64-c4cc172a1731"},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["discriminator.metrics_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_lfBo1k63k_t"},"outputs":[],"source":["# Set hyperparameters\n","batch_size = 128\n","sample_interval = 10\n","\n","# Train the Discriminator for the specified number of iterations\n","train(batch_size, sample_interval)"]},{"cell_type":"markdown","metadata":{"id":"meGyl2pPYqOk"},"source":["### Evaluation"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"K_FBBxybYl_K","executionInfo":{"status":"ok","timestamp":1659264899070,"user_tz":-540,"elapsed":651,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"outputs":[],"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","char = 1 #True image: A label for 1 is \"1\"\n","X_test_1 = X_test[np.where(y_test==char)]    \n","y_test_1 = y_test[np.where(y_test==char)]  \n","y_test_1 = np.ones((y_test_1.shape[0], 1))\n","\n","char = 7 #Fake image: A label for 7 is \"0\"\n","X_test_7 = X_test[np.where(y_test==char)]  \n","y_test_7 = y_test[np.where(y_test==char)]  \n","y_test_7 = np.zeros((y_test_7.shape[0], 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"daRBLxS_YsuA"},"outputs":[],"source":["_, accuracy = discriminator.evaluate(X_test_1, y_test_1)\n","print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tT_b906GYuJC"},"outputs":[],"source":["_, accuracy = discriminator.evaluate(X_test_7, y_test_7)\n","print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ITNAjFYu5aeU"},"outputs":[],"source":["#fake_img = np.zeros((batch_size, 28, 28)) -1\n"," #fake_img = np.random.normal(-1, 1, (batch_size, 28, 28))\n","(X_train, _), (X_test, _) = mnist.load_data()\n","char = 1 #True image\n","X_test_1 = X_test[np.where(y_test==char)]    \n","\n","char = 7 #Fake image\n","X_test_7 = X_test[np.where(y_test==char)]  \n","\n","test_size = 20\n","\n","#### test 1: real image\n","idx = np.random.randint(0, X_test_1.shape[0], test_size)\n","imgs_1 = X_test_1[idx]\n","\n","for i in range(test_size):\n","  print(i, end=\" \")\n","  show_img(imgs_1[i])\n","\n","y = discriminator.predict(imgs_1)\n","print(y)\n","\n","false = np.where(y<=0.5)\n","print(false)\n","\n","\n","#### test 7: fake image\n","idx = np.random.randint(0, X_test_7.shape[0], test_size)\n","imgs_7 = X_test_7[idx]\n","\n","for i in range(test_size):\n","  print(i, end=\" \")\n","  show_img(imgs_7[i])\n","\n","y = discriminator.predict(imgs_7)\n","print(y)\n","\n","false = np.where(y>=0.5)\n","print(false)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qcC-pNkFy8p"},"outputs":[],"source":["losses = np.array(losses)\n","\n","# Plot training losses for Discriminator and Generator\n","plt.figure(figsize=(15, 5))\n","plt.plot(iteration_checkpoints, losses, label=\"Discriminator loss\")\n","\n","\n","plt.xticks(iteration_checkpoints, rotation=90)\n","\n","plt.title(\"Training Loss\")\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Loss\")\n","plt.legend()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Practice04_Discriminator_NN.ipynb","provenance":[],"authorship_tag":"ABX9TyMZM5XxkR6eFVbM4NlCd1dO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}