{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practice07_Discriminator_CNN_cifar10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMbaQ6JZR+VzJp6AIAb/Vdr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/miokobayashii/summerschool2022/blob/main/day02/Practice07_Discriminator_CNN_cifar10.ipynb)"],"metadata":{"id":"gyv1dqLvDRPG"}},{"cell_type":"markdown","source":["## Discriminator | Convolutional Neural Network\n","We use cifar10 dataset"],"metadata":{"id":"B-KZpcE38j52"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ag7gEyhC7brG"},"outputs":[],"source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import random\n","\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","\n","from keras.layers import (\n","    Activation, BatchNormalization, Dense, Dropout, Flatten, Reshape, MaxPooling2D)\n","\n","from keras.layers.advanced_activations import LeakyReLU \n","\n","from keras.optimizers import adam_v2\n","from keras.layers.convolutional import Conv2D\n","from keras.utils.vis_utils import plot_model\n","\n","from keras.datasets import cifar10\n","\n","pd.set_option('display.max_columns', 32)"]},{"cell_type":"code","source":["img_rows = 32\n","img_cols = 32\n","channels = 3\n","\n","img_shape = (img_rows, img_cols, channels)"],"metadata":{"id":"9QNEOxo88os9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_discriminator(img_shape):\n","\n","    model = Sequential()\n","    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n","\n","    model.add(LeakyReLU(alpha=0.01))            \n","\n","    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n","\n","    #model.add(BatchNormalization())             \n","\n","    model.add(LeakyReLU(alpha=0.01))            \n","\n","    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n","\n","    #model.add(BatchNormalization())             \n","\n","    model.add(LeakyReLU(alpha=0.01))            \n","\n","    #model.add(MaxPooling2D(pool_size=2, strides=None, padding='valid'))\n","\n","    model.add(Flatten())                        \n","\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","\n","    return model"],"metadata":{"id":"yH6YVWMS8qkQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["discriminator = build_discriminator(img_shape)\n","discriminator.compile(loss='binary_crossentropy',\n","                      optimizer=adam_v2.Adam(),\n","                      metrics=['accuracy'])\n","discriminator.summary()\n","plot_model(discriminator, to_file='model.png', show_shapes=True)"],"metadata":{"id":"5WM4oS1d8sp4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = cifar10.load_data()"],"metadata":{"id":"vBZFSFDQ8ub-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape, y_train.shape, X_test.shape, y_test.shape"],"metadata":{"id":"hEfqG8fF8wES"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##cifar10_labels\n","0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'"],"metadata":{"id":"M-ya_Mon8x57"}},{"cell_type":"code","source":["def show_img(img_set, index):\n","  pos = 1\n","  i = index\n","  # draw cifar10 images and label names\n","  fig = plt.figure(figsize=(16,10))\n","  for img in img_set:\n","    \n","    plt.subplot(6, 10, pos)\n","    plt.imshow(img)\n","    plt.axis('off')# to hide tick values on X and Y axis\n","    plt.title( i )\n","    pos += 1\n","    i += 1\n","  plt.show()\n","  plt.close()"],"metadata":{"id":"ELaQRTZk80O6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","char = 3\n","X_train = X_train[(y_train == char ).flatten()]  \n","\n","index = random.randint(0, X_train.shape[0]/2)\n","i = index\n","img_set = X_train[index:index+60]\n","\n","show_img(img_set, index)"],"metadata":{"id":"bDtT0VP582Ep"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"id":"SK84IM8A84Jg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses = []\n","accuracies = []\n","iteration_checkpoints = []\n","\n","def train(batch_size, sample_interval, n_epochs = 10):\n","\n","    # Load the cifar10 dataset\n","    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","\n","    char = 3 #True image\n","    X_train_a = X_train[(y_train == char ).flatten()]    \n","\n","    char = 5 #Fake image\n","    X_train_b = X_train[(y_train == char ).flatten()]  \n","\n","    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n","    X_train_a = X_train_a / 127.5 - 1.0\n","    X_train_b = X_train_b / 127.5 - 1.0\n","   # X_train = np.expand_dims(X_train, axis=3)\n","\n","    #\n","    bat_per_epo = int((X_train_a.shape[0] + X_train_b.shape[0]) / batch_size)\n","    half_batch = int(batch_size / 2)\n","\n","    #print(bat_per_epo, half_batch )\n","    # Labels for real images: all ones\n","    real = np.ones((half_batch, 1))\n","    # Labels for fake images: all zeros\n","    fake = np.zeros((half_batch, 1))\n","    \n","    #bat_per_epo = 10\n","\n","    for i in range(n_epochs):\n","        for j in range(bat_per_epo):\n","\n","          # -------------------------\n","          #  Train the Discriminator\n","          # -------------------------\n","\n","          # Get a random batch of real images\n","          idx = np.random.randint(0, X_train_a.shape[0], half_batch)\n","          imgs = X_train_a[idx]\n","\n","          # Get a random batch of fake images\n","          idx = np.random.randint(0, X_train_b.shape[0], half_batch)\n","          fake_img = X_train_b[idx]\n","\n","          # Generate a batch of fake imagesã€€(random noize of [-1 1])\n","          #fake_img = np.random.normal(-1, 1, (batch_size, 28, 28))\n","          #fake_img = np.zeros((batch_size, 28, 28)) -1.0\n","          #print(fake_img.shape)\n","\n","          # Train Discriminator\n","          d_loss_real = discriminator.train_on_batch(imgs, real)\n","          d_loss_fake = discriminator.train_on_batch(fake_img , fake)\n","        # print(d_loss_real, d_loss_fake)\n","          d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","\n","          if (i*10 +  j + 1) % sample_interval == 0 :\n","\n","            # Save losses and accuracies so they can be plotted after training\n","            losses.append((d_loss))\n","            accuracies.append(100.0 * accuracy)\n","            iteration_checkpoints.append(i*10 +  j + 1)\n","\n","            # Output training progress\n","            print(\"Epoch:%d %d/%d [D loss: %f, acc.: %.2f%%]\" %\n","                  (i + 1, j+1, bat_per_epo, d_loss, 100.0 * accuracy))"],"metadata":{"id":"ik4CkK-E86wO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set hyperparameters\n","batch_size = 128\n","sample_interval = 50\n","\n","# Train the Discriminator for the specified number of iterations\n","train(batch_size, sample_interval)"],"metadata":{"id":"Ykmutt90889Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) =  cifar10.load_data()\n","char = 3 #True image: A label for A is \"1\"\n","X_test_a = X_test[(y_test == char ).flatten()]    \n","y_test_a = y_test[(y_test == char ).flatten()]  \n","y_test_a = np.ones((y_test_a.shape[0], 1))\n","\n","char = 5 #Fake image: A label for B is \"0\"\n","X_test_b = X_test[(y_test == char ).flatten()]  \n","y_test_b = y_test[(y_test == char ).flatten()]  \n","y_test_b = np.zeros((y_test_b.shape[0], 1))"],"metadata":{"id":"Nm6RnEHU8-6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_, accuracy = discriminator.evaluate(X_test_a, y_test_a)\n","print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"],"metadata":{"id":"mGqB4pUX9BBW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_, accuracy = discriminator.evaluate(X_test_b, y_test_b)\n","print(\"Training Accuracy: %.2f%%\" % (100 * accuracy))"],"metadata":{"id":"WFf-q72p9C1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_img_for_test(img, pos,  figsize=(16,10),):\n","  \n","    fig = plt.figure(figsize=figsize,dpi=100)\n","    plt.subplot(6, 10, pos)\n","    plt.imshow(img)\n","    plt.imshow(img)\n","    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n","    plt.show()"],"metadata":{"id":"wsPsibza-V5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_img_for_test(img_set, test_size):\n","  pos = 1\n","  i = index\n","  # draw cifar10 images and label names\n","  fig = plt.figure(figsize=(16,10))\n","  for img in img_set:\n","    \n","    plt.subplot(6, 10, pos)\n","    plt.imshow(img)\n","    plt.axis('off')# to hide tick values on X and Y axis\n","    plt.title( i )\n","    pos += 1\n","    i += 1\n","  plt.show()\n","  plt.close()"],"metadata":{"id":"JHA5M3G-AE8C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#fake_img = np.zeros((batch_size, 28, 28)) -1\n"," #fake_img = np.random.normal(-1, 1, (batch_size, 28, 28))\n","(X_train, _), (X_test, _) =  cifar10.load_data()\n","char = 3 #True image\n","X_test_a = X_test[(y_test == char ).flatten()]    \n","\n","char = 5 #Fake image\n","X_test_b = X_test[(y_test == char ).flatten()]  \n","\n","test_size = 10\n","\n","#### test : real image\n","idx = np.random.randint(0, X_test_a.shape[0], test_size)\n","imgs_a = X_test_a[idx]\n","\n","show_img_for_test(imgs_a,test_size)\n","\n","y = discriminator.predict(imgs_a)\n","print(y)\n","\n","false = np.where(y<=0.5)\n","print(false)\n","\n","\n","#### test : fake image\n","idx = np.random.randint(0, X_test_b.shape[0], test_size)\n","imgs_b = X_test_b[idx]\n","\n","show_img_for_test(imgs_b,test_size)\n","\n","y = discriminator.predict(imgs_b)\n","print(y)\n","false = np.where(y>=0.5)\n","print(false)"],"metadata":{"id":"2bbDgYId9Eb5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses = np.array(losses)\n","\n","# Plot training losses for Discriminator and Generator\n","plt.figure(figsize=(15, 5))\n","plt.plot(iteration_checkpoints, losses, label=\"Discriminator loss\")\n","\n","\n","plt.xticks(iteration_checkpoints, rotation=90)\n","\n","plt.title(\"Training Loss\")\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Loss\")\n","plt.legend()"],"metadata":{"id":"iUV2_69a9GQm"},"execution_count":null,"outputs":[]}]}