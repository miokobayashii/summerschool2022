{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practice05_practiceCNN.ipynb","provenance":[],"authorship_tag":"ABX9TyNiNuLMiE5PoRtn37MpvkR/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Practice CNN\n","without training process\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/miokobayashii/summerschool2022/blob/main/day02/Practice05_practiceCNN.ipynb)"],"metadata":{"id":"42W0igSm4-Jb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5Qq39uh2r2k"},"outputs":[],"source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","from keras.datasets import mnist\n","\n","from keras.layers import Dense, Flatten, Reshape, Input\n","from keras.models import Sequential\n","from keras.layers.convolutional import Conv2D, Conv2DTranspose\n","\n","pd.set_option('display.max_columns', 28)"]},{"cell_type":"markdown","source":["## Four types of filters"],"metadata":{"id":"NNQy-zBC20-i"}},{"cell_type":"code","source":["def TopEdge_filter(shape, dtype=None):\n","    f = np.array([\n","            [[[-1.0]], [[-1.0]], [[-1.0]]],\n","            [[[1.0]], [[1.0]], [[1.0]]],\n","            [[[0.0]], [[0.0]], [[0.0]]]\n","        ])\n","    return f\n","\n","def BottomEdge_filter(shape, dtype=None):\n","    f = np.array([\n","            [[[0.0]], [[0.0]], [[0.0]]],\n","            [[[1.0]], [[1.0]], [[1.0]]],\n","            [[[-1.0]], [[-1.0]], [[-1.0]]]\n","        ])\n","    return f\n","\n","def LeftEdge_filter(shape, dtype=None):\n","    f = np.array([\n","            [[[-1.0]], [[1.0]], [[0.0]]],\n","            [[[-1.0]], [[1.0]], [[0.0]]],\n","            [[[-1.0]], [[1.0]], [[0.0]]]\n","        ])\n","    return f\n","\n","def RightEdge_filter(shape, dtype=None):\n","    f = np.array([\n","            [[[0.0]], [[1.0]], [[-1.0]]],\n","            [[[0.0]], [[1.0]], [[-1.0]]],\n","            [[[0.0]], [[1.0]], [[-1.0]]]\n","        ])\n","    return f"],"metadata":{"id":"f1ViG7iN23Xb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load MNIST"],"metadata":{"id":"Fx-2e-QO26_A"}},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"metadata":{"id":"Wr39ldTL3ZIp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###A function to show an image"],"metadata":{"id":"To5bH64V3akm"}},{"cell_type":"code","source":["def show_img(img, figsize=(2,2)):\n","    fig = plt.figure(figsize=figsize,dpi=100)\n","    plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n","    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n","    plt.show()"],"metadata":{"id":"6TYwDlxr3c2M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Show an image"],"metadata":{"id":"WC9AjkP53d_Z"}},{"cell_type":"code","source":["char = 0\n","X_test = X_test[np.where(y_test==char)]  \n","#[idx] = np.random.randint(0, X_test.shape[0], 1)\n","show_img(X_test[0])"],"metadata":{"id":"5CaqEywu3gH9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Show the pixel numebers of the image."],"metadata":{"id":"xtkKVNYl3iTA"}},{"cell_type":"code","source":["pd.DataFrame(X_test[0])"],"metadata":{"id":"86_1v4rH3h2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test[0].shape"],"metadata":{"id":"kxOp0mVJ3ka-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Convert the shape of an input data."],"metadata":{"id":"lA1ltULl3maW"}},{"cell_type":"code","source":["input_mat = X_test[0].reshape((1, 28, 28, 1))"],"metadata":{"id":"RjxYXC-23mPJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`X_test[0].reshape((1, 28, 28, 1))`\n","\n","The first 1 means a batch size. In an actual trainig process, this number will be such as 64, 128, 256 that represent the number of the training data set to input for one training.\n","Next, \"28, 28\" means the image size. Last \"1\" means the number of channel. If we deal with a color image, it is 3 because a color image has three channels for RGB.\n","\n"],"metadata":{"id":"GLR8SALm3qaa"}},{"cell_type":"markdown","source":["### Change the range [0, 255] to [0, 1]"],"metadata":{"id":"RpmgzmAt3s-Q"}},{"cell_type":"code","source":["input_mat = np.round(input_mat/255.0, decimals=2) \n","\n","input_mat_disp = input_mat.reshape((input_mat.shape[1],input_mat.shape[2]))\n","pd.DataFrame(input_mat_disp)"],"metadata":{"id":"uaTtyErJ3sSw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_mat.shape"],"metadata":{"id":"VgJ0QrgE3xPw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Input(shape=(28,28,1)))                           \n","\n","cnn_1 = Conv2D(1, kernel_size=3, strides=2, kernel_initializer=BottomEdge_filter, padding='same')\n","model.add(cnn_1)\n","model.build()"],"metadata":{"id":"l1Nd0Nt03yOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["out = model.predict(input_mat)\n","out = np.round(out.reshape((out.shape[1],out.shape[2])), decimals=2 )\n","show_img(out)\n","pd.DataFrame(out)"],"metadata":{"id":"zEDbsx0-3zoa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Questions\n","---\n","<img src=\"https://drive.google.com/uc?id=1L8L4vIUsHhtZCZ5oB_rdLlLJGmXO58sm\" width=\"800\">"],"metadata":{"id":"eipi2Yb-38K6"}},{"cell_type":"markdown","source":["(1) Focusing on (10, 10), please confirm the convolution with a top edge filter. How did you calculate those values?\n","\n","Answer:"],"metadata":{"id":"SlumMMn831hz"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","<img src=\"https://drive.google.com/uc?id=1q2ejp_8huZ-3C6DSYPsXJ-K8xauO4s6O\" width=\"700\">"],"metadata":{"id":"KgdYGER64X8e"}},{"cell_type":"markdown","source":["(2) Focusing on (10, 10), please confirm the convolution with a end edge filter. How did you calculate those values?\n","\n","Answer:\n","\n","(3) Focusing on (10, 10), please confirm the convolution with a left edge filter. How did you calculate those values?\n","\n","Answer:\n","\n","(4) Focusing on (10, 10), please confirm the convolution with a right edge filter. How did you calculate those values?\n","\n","Answer:\n","\n"],"metadata":{"id":"CoweJ9dt337O"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","<img src=\"https://drive.google.com/uc?id=1lgV8MS1Kyhy7HScrTEf1oGwINYT-OnAu\" width=\"800\">"],"metadata":{"id":"BHd9cYfQ4mGc"}},{"cell_type":"markdown","source":["(5) When you change the stride size from 1 to 2, what is the size of an output image after doing convolution? Please write the answer and the reason.\n","\n","Answer:\n","\n","(6) When you set the stride size to 2, which area on the convoluted image corresponds to the 3x3 area centered at (9, 9) on the input image? Please write the answer and the reason.\n","\n","Answer:\n","\n","Questions or Comments"],"metadata":{"id":"XjfloT7R36O7"}}]}