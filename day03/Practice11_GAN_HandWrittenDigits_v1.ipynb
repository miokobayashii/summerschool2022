{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practice11_GAN_HandWrittenDigits_v1.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1XwPNdfkdnPzTt9iGFLzH88XgO-AyVf7_","authorship_tag":"ABX9TyP8sRsQsfjVVtD3uQZlrxFk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/miokobayashii/summerschool2022/blob/main/day03/Practice11_GAN_HandWrittenDigits_v1.ipynb)\n"],"metadata":{"id":"LqMVuADM5-jm"}},{"cell_type":"markdown","source":["# Introduction to Generative Adversarial Networks"],"metadata":{"id":"d48Hkss1Q5CE"}},{"cell_type":"markdown","source":["Run the program and confirm the result.\n","If the result is not good, add a hidden layer between the input and the existing hidden layer of the generator network."],"metadata":{"id":"tifORZGzISTX"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1Q9Rp8KH1ERL1-198C8KA-JvJUderolXo\" width=\"800\"> "],"metadata":{"id":"VwTfKMBfHNpF"}},{"cell_type":"markdown","source":["## Generate handwritten digits images from noize images"],"metadata":{"id":"i-kmWlGoRC7S"}},{"cell_type":"markdown","source":["- This source codes refer to \"GANs in Action: Deep learning with Generative Adversarial Networks\" , Bok, Vladimir; Langr, Jakub. \n","https://www.amazon.co.uk/GANs-Action-learning-Generative-Adversarial-ebook/dp/B09781PX97/ref=sr_1_1?crid=1VXTH6YGJ4WIL&keywords=GANs+in+Action%3A+Deep+learning+with+Generative+Adversarial+Networks&qid=1654557614&sprefix=gans+in+action+deep+learning+with+generative+adversarial+networks%2Caps%2C263&sr=8-1"],"metadata":{"id":"-8Wp_i6wSkK_"}},{"cell_type":"markdown","source":["### Import all the packages and libraries\n","\"keras.datasets import mnist\" means that we import the MNITST dataset of handwritten digits."],"metadata":{"id":"TM1TdOHJUvMk"}},{"cell_type":"code","source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from keras.datasets import mnist, fashion_mnist\n","\n","from keras.layers import Dense, Flatten, Reshape\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.models import Sequential, load_model\n","#from keras.optimizers import Adam\n","from keras.optimizers import adam_v2\n","\n"],"metadata":{"id":"FodYL2qSRBod","executionInfo":{"status":"ok","timestamp":1659837494131,"user_tz":-540,"elapsed":2624,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["### Define the dimentions of our model and dataset.\n"],"metadata":{"id":"JOIRecyPVUR8"}},{"cell_type":"code","source":["img_rows = 28\n","img_cols = 28\n","channels = 1\n","\n","img_shape = (img_rows, img_cols, channels)    \n","\n","z_dim = 100\n"],"metadata":{"id":"hukvHjxDVSEp","executionInfo":{"status":"ok","timestamp":1659837544077,"user_tz":-540,"elapsed":2,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### Generator\n","\n","Fill the blanks"],"metadata":{"id":"lHs_xbm_xBPh"}},{"cell_type":"code","source":["def build_generator(img_shape, z_dim):\n","\n","    model = Sequential()\n","\n","    # Fully connected layer\n","    model.add(Dense(     , input_dim=z_dim))  #Fill the blank\n","\n","    # Leaky ReLU activation\n","    model.add(LeakyReLU(alpha=0.01))\n","\n","   #model.add(Dense(128, input_dim=z_dim))　　　　　#If the result was not good enough, uncomment these three lines, and run the progam again. \n","   #Leaky ReLU activation\n","   #model.add(LeakyReLU(alpha=0.01))\n","\n","    # Output layer with tanh activation\n","    model.add(Dense(      , activation='tanh'))   #Fill the blank\n","\n","    # Reshape the Generator output to image dimensions\n","    model.add(Reshape(img_shape))\n","    model.compile() \n","    return model"],"metadata":{"id":"1yVyZ42WccEk","executionInfo":{"status":"ok","timestamp":1659837547162,"user_tz":-540,"elapsed":221,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Build the Generator\n","generator = build_generator(img_shape, z_dim)\n","generator.summary()\n","\n","from keras.utils.vis_utils import plot_model\n","plot_model(generator, to_file='model.png', show_shapes=True)\n"],"metadata":{"id":"yXRx2RD-xP42"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Discriminator"],"metadata":{"id":"qciNp6IhxERt"}},{"cell_type":"code","source":["def build_discriminator(img_shape):\n","\n","    model = Sequential()\n","\n","    # Flatten the input image\n","    model.add(Flatten(input_shape=img_shape))\n","\n","    # Fully connected layer\n","    model.add(Dense(128))\n","\n","    # Leaky ReLU activation\n","    model.add(LeakyReLU(alpha=0.01))\n","\n","    # Output layer with sigmoid activation\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    return model"],"metadata":{"id":"yhGnp3topv_J","executionInfo":{"status":"ok","timestamp":1659837577731,"user_tz":-540,"elapsed":341,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Build the Discriminator\n","discriminator = build_discriminator(img_shape)\n","discriminator.summary()\n","plot_model(discriminator, to_file='model.png', show_shapes=True)"],"metadata":{"id":"Ht-WhCuia8v9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Build GAN"],"metadata":{"id":"lbUdHLsOxHgB"}},{"cell_type":"code","source":["def build_gan(generator, discriminator):\n","\n","    model = Sequential()\n","\n","    # Combined Generator -> Discriminator model\n","    model.add(generator)\n","    model.add(discriminator)\n","\n","    return model"],"metadata":{"id":"1vSVcOucqAxX","executionInfo":{"status":"ok","timestamp":1659837583485,"user_tz":-540,"elapsed":237,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#Compile the Discriminator\n","discriminator.compile(loss='binary_crossentropy',\n","                      optimizer=adam_v2.Adam(),\n","                      metrics=['accuracy'])\n","\n","\n","# Keep Discriminator’s parameters constant for Generator training\n","discriminator.trainable = False\n","\n","# Build and compile GAN model with fixed Discriminator to train the Generator\n","\n","\n","gan = build_gan(generator, discriminator)\n","gan.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam())"],"metadata":{"id":"WNZtHpelQmxR","executionInfo":{"status":"ok","timestamp":1659837585573,"user_tz":-540,"elapsed":221,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# If you want to use saved discriminator and generator models after you saved models, uncomment below and run instead of the program above.\n","\n","#discriminator = load_model('/content/drive/MyDrive/Colab Notebooks/summerschool2022/day03/handwritten_discriminator.h5')\n","#generator = load_model('/content/drive/MyDrive/Colab Notebooks/summerschool2022/day03/handwritten_generator.h5')\n","#discriminator.trainable = False\n","#gan = build_gan(generator, discriminator)\n","#gan.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam())\n"],"metadata":{"id":"Siv_iLgdHNmX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training "],"metadata":{"id":"nFYNUcF3xKeF"}},{"cell_type":"code","source":["losses = []\n","accuracies = []\n","iteration_checkpoints = []\n","\n","\n","def train(iterations, batch_size, sample_interval):\n","\n","    # Load the MNIST dataset\n","    (X_train, _), (_, _) = mnist.load_data()\n","    #(X_train, _), (_, _) = fashion_mnist.load_data()\n","    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n","    X_train = X_train / 127.5 - 1.0\n","    X_train = np.expand_dims(X_train, axis=3)\n","\n","    # Labels for real images: all ones\n","    real = np.ones((batch_size, 1))\n","\n","    # Labels for fake images: all zeros\n","    fake = np.zeros((batch_size, 1))\n","\n","    for iteration in range(iterations):\n","\n","        # -------------------------\n","        #  Train the Discriminator\n","        # -------------------------\n","\n","        # Get a random batch of real images\n","        idx = np.random.randint(0, X_train.shape[0], batch_size)\n","        imgs = X_train[idx]\n","\n","        # Generate a batch of fake images\n","        z = np.random.normal(0, 1, (batch_size, 100))\n","        gen_imgs = generator.predict(z)\n","\n","        # Train Discriminator\n","        d_loss_real = discriminator.train_on_batch(imgs, real)\n","        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n","        d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","        # ---------------------\n","        #  Train the Generator\n","        # ---------------------\n","\n","        # Generate a batch of fake images\n","        z = np.random.normal(0, 1, (batch_size, 100))\n","        gen_imgs = generator.predict(z)\n","\n","        # Train Generator\n","        g_loss = gan.train_on_batch(z, real)\n","\n","        if (iteration + 1) % sample_interval == 0 or iteration == 0 :\n","\n","            # Save losses and accuracies so they can be plotted after training\n","            losses.append((d_loss, g_loss))\n","            accuracies.append(100.0 * accuracy)\n","            iteration_checkpoints.append(iteration + 1)\n","\n","            # Output training progress\n","            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n","                  (iteration + 1, d_loss, 100.0 * accuracy, g_loss))\n","\n","            # Output a sample of generated image\n","            sample_images(generator)\n","            "],"metadata":{"id":"tHci_BXBCFXO","executionInfo":{"status":"ok","timestamp":1659837588491,"user_tz":-540,"elapsed":306,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def sample_images(generator, image_grid_rows=4, image_grid_columns=4):\n","\n","    # Sample random noise\n","    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n","\n","    # Generate images from random noise\n","    gen_imgs = generator.predict(z)\n","\n","    # Rescale image pixel values to [0, 1]\n","    gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","    # Set image grid\n","    fig, axs = plt.subplots(image_grid_rows,\n","                            image_grid_columns,\n","                            figsize=(image_grid_columns,image_grid_rows),\n","                            sharey=True,\n","                            sharex=True,facecolor='skyblue')\n","\n","    cnt = 0\n","    for i in range(image_grid_rows):\n","        for j in range(image_grid_columns):\n","            # Output a grid of images\n","            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n","            axs[i, j].axis('off')\n","            cnt += 1\n","    plt.show()\n","  "],"metadata":{"id":"RVk7jGORt296","executionInfo":{"status":"ok","timestamp":1659837591647,"user_tz":-540,"elapsed":320,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Set hyperparameters\n","iterations = 10000\n","batch_size = 256\n","sample_interval = 100\n","\n","# Train the GAN for the specified number of iterations\n","train(iterations, batch_size, sample_interval)\n","\n","# If you want to save a generator and discriminator, uncommet the lines below.\n","generator.save('/content/drive/MyDrive/Colab Notebooks/summerschool2022/day03/handwritten_generator.h5')\n","#discriminator.trainable = True\n","#discriminator.compile(loss='binary_crossentropy',optimizer=adam_v2.Adam(),metrics=['accuracy'])\n","discriminator.save('/content/drive/MyDrive/Colab Notebooks/summerschool2022/day03/handwritten_discriminator.h5')\n"],"metadata":{"id":"T8s77kg1GStP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualization of training process"],"metadata":{"id":"HN28Uzn1xRhs"}},{"cell_type":"code","source":["losses = np.array(losses)\n","\n","# Plot training losses for Discriminator and Generator\n","plt.figure(figsize=(15, 5))\n","plt.plot(iteration_checkpoints, losses.T[0], label=\"Discriminator loss\")\n","plt.plot(iteration_checkpoints, losses.T[1], label=\"Generator loss\")\n","\n","plt.xticks(iteration_checkpoints, rotation=90)\n","\n","plt.title(\"Training Loss\")\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Loss\")\n","plt.legend()"],"metadata":{"id":"kqlDigvMUXzT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import load_model\n","generator = load_model('/content/drive/MyDrive/Colab Notebooks/summerschool2022/day03/handwritten_generator.h5')\n","sample_images(generator, image_grid_rows=10, image_grid_columns=10)"],"metadata":{"id":"_T74w9vKe625"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Write down your consideration and commnet:"],"metadata":{"id":"F5ZSBs9eIbop"}}]}