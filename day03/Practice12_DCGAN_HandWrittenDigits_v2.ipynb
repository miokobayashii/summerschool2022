{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practice12_DCGAN_HandWrittenDigits_v2.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1XwPNdfkdnPzTt9iGFLzH88XgO-AyVf7_","authorship_tag":"ABX9TyPGsWn/GhOeqXBVeYWp3LAJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/miokobayashii/summerschool2022/blob/main/day03/Practice12_DCGAN_HandWrittenDigits_v2.ipynb)\n"],"metadata":{"id":"LqMVuADM5-jm"}},{"cell_type":"markdown","source":["# Introduction to Generative Adversarial Networks\n","\n","<img src=\"https://drive.google.com/uc?id=16M7Ybyufei3gd7DNtyBwn9gMk4K2gylx\" width=\"800\">"],"metadata":{"id":"d48Hkss1Q5CE"}},{"cell_type":"markdown","source":["## Generate handwritten digits images from noize images"],"metadata":{"id":"i-kmWlGoRC7S"}},{"cell_type":"markdown","source":["- This source codes is based on the book, \"GANs in Action: Deep learning with Generative Adversarial Networks\" , Bok, Vladimir; Langr, Jakub. \n","https://www.amazon.co.uk/GANs-Action-learning-Generative-Adversarial-ebook/dp/B09781PX97/ref=sr_1_1?crid=1VXTH6YGJ4WIL&keywords=GANs+in+Action%3A+Deep+learning+with+Generative+Adversarial+Networks&qid=1654557614&sprefix=gans+in+action+deep+learning+with+generative+adversarial+networks%2Caps%2C263&sr=8-1"],"metadata":{"id":"-8Wp_i6wSkK_"}},{"cell_type":"markdown","source":["### Import all the packages and libraries\n","\"keras.datasets import mnist\" means that we import the MNITST dataset of handwritten digits."],"metadata":{"id":"TM1TdOHJUvMk"}},{"cell_type":"code","source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from keras.datasets import mnist, fashion_mnist\n","\n","from keras.layers import  BatchNormalization, Dense, Flatten, Reshape\n","from keras.layers.convolutional import Conv2D, Conv2DTranspose\n","\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.models import Sequential, load_model\n","#from keras.optimizers import Adam\n","from keras.optimizers import adam_v2\n","\n"],"metadata":{"id":"FodYL2qSRBod","executionInfo":{"status":"ok","timestamp":1659840672744,"user_tz":-540,"elapsed":3145,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["### Define the dimentions of our model and dataset.\n"],"metadata":{"id":"JOIRecyPVUR8"}},{"cell_type":"code","source":["img_rows = 28\n","img_cols = 28\n","channels = 1\n","\n","img_shape = (img_rows, img_cols, channels)    \n","\n","z_dim = 100\n"],"metadata":{"id":"hukvHjxDVSEp","executionInfo":{"status":"ok","timestamp":1659840721629,"user_tz":-540,"elapsed":576,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### Generator\n","Please fill in the blanks"],"metadata":{"id":"lHs_xbm_xBPh"}},{"cell_type":"code","source":["def build_generator(img_shape, z_dim):\n","\n","    model = Sequential()\n","\n","    # Fully connected layer\n","    model.add(Dense(    , input_dim=z_dim))\n","    model.add(Reshape((  ,    ,    )))\n","\n","    # You can choose one.\n","    #model.add(Conv2DTranspose( 64 , kernel_size=4, strides=1, padding='valid', output_padding=0))   ## output 7 channels \n","    #model.add(Conv2DTranspose( 64 , kernel_size=1, strides=2, padding='valid', output_padding=0))   ## output 7 channels\n","    #model.add(Conv2DTranspose( 64 , kernel_size=3, strides=2, padding='same', output_padding=0))   ## output 7 channels \n","\n","    #If you do not specipy the output_padding above, the number of output channels changes.\n","    #model.add(Conv2DTranspose( 64 , kernel_size=3, strides=2, padding='same'))   ## output 8 channels \n","\n","    model.add(BatchNormalization())    \n","\n","    # Leaky ReLU activation\n","    model.add(LeakyReLU(alpha=0.1))\n","\n","    model.add(Conv2DTranspose( 32 , kernel_size=3, strides=2, padding='same'))\n","    model.add(BatchNormalization())    \n","\n","    # Leaky ReLU activation\n","    model.add(LeakyReLU(alpha=0.1))\n","\n","    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same',  activation='tanh'))\n","\n","    model.compile() \n","    return model"],"metadata":{"id":"1yVyZ42WccEk","executionInfo":{"status":"ok","timestamp":1659841230006,"user_tz":-540,"elapsed":347,"user":{"displayName":"Mio Kobayashi","userId":"05551213832821669975"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Build the Generator\n","generator = build_generator(img_shape, z_dim)\n","\n","generator.summary()\n","\n","from keras.utils.vis_utils import plot_model\n","plot_model(generator, to_file='model.png', show_shapes=True)\n"],"metadata":{"id":"yXRx2RD-xP42"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Discriminator\n","\n","Fill out the blanks"],"metadata":{"id":"qciNp6IhxERt"}},{"cell_type":"code","source":["def build_discriminator(img_shape):\n","\n","    model = Sequential()\n","    model.add(Conv2D(   , kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n","\n","    model.add(LeakyReLU(alpha=0.2))            \n","\n","    model.add(Conv2D(  , kernel_size=3, strides=2, padding='same'))\n","\n","    #model.add(BatchNormalization())             \n","\n","    model.add(LeakyReLU(alpha=0.2))            \n","\n","    model.add(Conv2D(   , kernel_size=3, strides=2, padding='same'))\n","\n","    #model.add(BatchNormalization())             \n","\n","    model.add(LeakyReLU(alpha=0.2))            \n","\n","    #model.add(MaxPooling2D(pool_size=2, strides=None, padding='valid'))\n","\n","    model.add(Flatten())                        \n","\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","\n","    return model"],"metadata":{"id":"yhGnp3topv_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build the Discriminator\n","discriminator = build_discriminator(img_shape)\n","\n","discriminator.summary()\n","plot_model(discriminator, to_file='model.png', show_shapes=True)"],"metadata":{"id":"Ht-WhCuia8v9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Build GAN"],"metadata":{"id":"lbUdHLsOxHgB"}},{"cell_type":"code","source":["def build_gan(generator, discriminator):\n","\n","    model = Sequential()\n","\n","    # Combined Generator -> Discriminator model\n","    model.add(generator)\n","    model.add(discriminator)\n","\n","    return model"],"metadata":{"id":"1vSVcOucqAxX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Compile the Discriminator\n","discriminator.compile(loss='binary_crossentropy',\n","                      optimizer=adam_v2.Adam(learning_rate=0.001, beta_1=0.5),\n","                      metrics=['accuracy'])\n","\n","\n","# Keep Discriminatorâ€™s parameters constant for Generator training\n","discriminator.trainable = False\n","\n","# Build and compile GAN model with fixed Discriminator to train the Generator\n","gan = build_gan(generator, discriminator)\n","gan.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam(learning_rate=0.001, beta_1=0.5))"],"metadata":{"id":"WNZtHpelQmxR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# If you want to load discriminator and generator models after you saved models and train them again, uncomment below and run instead of the program above.\n","\n","#discriminator = load_model('/content/drive/MyDrive/Colab Notebooks/summerschool2022/day03/handwritten_discriminator_dcgan.h5')\n","#generator = load_model('/content/drive/MyDrive/Colab Notebooks/summerschool2022/day03/handwritten_generator_dcgan.h5')\n","#discriminator.trainable = False\n","#gan = build_gan(generator, discriminator)\n","#gan.compile(loss='binary_crossentropy', optimizer=adam_v2.Adam())\n"],"metadata":{"id":"Siv_iLgdHNmX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training "],"metadata":{"id":"nFYNUcF3xKeF"}},{"cell_type":"code","source":["losses = []\n","accuracies = []\n","iteration_checkpoints = []\n","\n","\n","def train(iterations, batch_size, sample_interval):\n","\n","    # Load the MNIST dataset\n","    (X_train, _), (_, _) = mnist.load_data()\n","    #(X_train, _), (_, _) = fashion_mnist.load_data()\n","    # Rescale [0, 255] grayscale pixel values to [-1, 1]\n","    X_train = X_train / 127.5 - 1.0\n","    X_train = np.expand_dims(X_train, axis=3)\n","\n","    # Labels for real images: all ones\n","    real = np.ones((batch_size, 1))\n","\n","    # Labels for fake images: all zeros\n","    fake = np.zeros((batch_size, 1))\n","\n","    for iteration in range(iterations):\n","\n","        # -------------------------\n","        #  Train the Discriminator\n","        # -------------------------\n","\n","        # Get a random batch of real images\n","        idx = np.random.randint(0, X_train.shape[0], batch_size)\n","        imgs = X_train[idx]\n","\n","        # Generate a batch of fake images\n","        z = np.random.normal(0, 1, (batch_size, 100))\n","        gen_imgs = generator.predict(z)\n","\n","        # Train Discriminator\n","        d_loss_real = discriminator.train_on_batch(imgs, real)\n","        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n","        d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","        # ---------------------\n","        #  Train the Generator\n","        # ---------------------\n","\n","        # Generate a batch of fake images\n","        z = np.random.normal(0, 1, (batch_size, 100))\n","        gen_imgs = generator.predict(z)\n","\n","        # Train Generator\n","        g_loss = gan.train_on_batch(z, real)\n","\n","        if (iteration + 1) % sample_interval == 0 or iteration == 0 :\n","\n","            # Save losses and accuracies so they can be plotted after training\n","            losses.append((d_loss, g_loss))\n","            accuracies.append(100.0 * accuracy)\n","            iteration_checkpoints.append(iteration + 1)\n","\n","            # Output training progress\n","            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n","                  (iteration + 1, d_loss, 100.0 * accuracy, g_loss))\n","\n","            # Output a sample of generated image\n","            sample_images(generator)\n","            "],"metadata":{"id":"tHci_BXBCFXO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sample_images(generator, image_grid_rows=4, image_grid_columns=4):\n","\n","    # Sample random noise\n","    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n","\n","    # Generate images from random noise\n","    gen_imgs = generator.predict(z)\n","\n","    # Rescale image pixel values to [0, 1]\n","    gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","    # Set image grid\n","    fig, axs = plt.subplots(image_grid_rows,\n","                            image_grid_columns,\n","                            figsize=(image_grid_columns,image_grid_rows),\n","                            sharey=True,\n","                            sharex=True,facecolor='skyblue')\n","\n","    cnt = 0\n","    for i in range(image_grid_rows):\n","        for j in range(image_grid_columns):\n","            # Output a grid of images\n","            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n","            axs[i, j].axis('off')\n","            cnt += 1\n","    plt.show()\n","  "],"metadata":{"id":"RVk7jGORt296"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set hyperparameters\n","iterations = 5000\n","batch_size = 256\n","sample_interval = 100\n","\n","# Train the GAN for the specified number of iterations\n","train(iterations, batch_size, sample_interval)\n","\n","# If you want to save a generator and discriminator, uncommet the lines below.\n","generator.save('/content/drive/MyDrive/Colab Notebooks/summerschool2022/day03/handwritten_generator_dcgan.h5')\n","#discriminator.trainable = True\n","#discriminator.compile(loss='binary_crossentropy',optimizer=adam_v2.Adam(),metrics=['accuracy'])\n","discriminator.save('/content/drive/MyDrive/Colab Notebooks/summerschool2022/day03/handwritten_discriminator_dcgan.h5')\n"],"metadata":{"id":"T8s77kg1GStP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualization of training process"],"metadata":{"id":"HN28Uzn1xRhs"}},{"cell_type":"code","source":["losses = np.array(losses)\n","\n","# Plot training losses for Discriminator and Generator\n","plt.figure(figsize=(15, 5))\n","plt.plot(iteration_checkpoints, losses.T[0], label=\"Discriminator loss\")\n","plt.plot(iteration_checkpoints, losses.T[1], label=\"Generator loss\")\n","\n","plt.xticks(iteration_checkpoints, rotation=90)\n","\n","plt.title(\"Training Loss\")\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Loss\")\n","plt.legend()"],"metadata":{"id":"kqlDigvMUXzT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import load_model\n","generator = load_model('/content/drive/MyDrive/Colab Notebooks/summerschool2022/day03/handwritten_generator_dcgan.h5')\n","sample_images(generator, image_grid_rows=10, image_grid_columns=10)"],"metadata":{"id":"_T74w9vKe625"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Write down your consideration and commnet:"],"metadata":{"id":"DahkPl11QWXN"}}]}